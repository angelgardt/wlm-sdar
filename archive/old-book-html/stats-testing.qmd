# Тестирование статистических гипотез {#stats-testing}

{{< include _symbols.qmd >}}

```{r stats-testing-pkgs, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())
library(latex2exp)
```

В ходе статистического анализа мы, главным образом, заняты тем, что тестируем статистические гипотезы. Ведь на какого рода вопросы мы отвечаем с помощью анализа?

- Различаются ли группы между собой?
- Значимо ли влияние какого-либо фактора? → Различаются ли группы между собой?
- Хороша ли та модель, которую мы построили? → Отличается ли она от нулевой модели?

И так далее. Так или иначе, всё сводится в тому, что мы ищем какие-то различия. Но силу того, что у нас неопределённость и вариация в данных, мы просто так «в лоб» сказать о различиях по оценкам параметров не можем. Приходится тестировать статистические гипотезы.

## Нулевая и альтернативная гипотезы {#stats-testing-hyotheses}

Еще раз тезисно [вспомним о гипотезах](#stats-hypotheses) в целом:

- **Гипотеза** ($H$) --- это предположение, которое подлежит проверке на основе результатов наблюдений.
- Гипотезы бывают:
    - **теоретические** --- про конструкты
    - **эмпирические** --- про переменные
    - **статистические** --- про параметры [генеральной совокупности] и данные

Статистические гипотезы бывают простыми и сложными:

- **Простая гипотеза** --- это такое предположение, которое включает в себя какое-либо однозначно определеяемое утверждение. Например, истинная величина параметра соответствует некоторому строго заданному значению: $H : \theta = \theta_0$. Другой вариант --- две генеральные совокупности имеют одно и то же значение одной и той же характеристики: $H : \theta_1 = \theta_2$.
- **Сложная гипотеза** предполагает множественность вариантов для параметра, которые укладываются в рамки проверяемого предположения. Например, $H : \theta > \theta_0$ или $H : \theta_1 \neq \theta_2$.

В рамках самого хода тестирования гипотез существует **проверяемая (нулевая) гипотеза** ($H_0$). Её обычно стараются предельно упростить, поэтому она формулируется как простая гипотеза. В противовес ей выдвигается **альтернативная гипотеза** ($H_1$), которая будет иметь вид сложной гипотезы.

Для проверки гипотезы необходимы две вещи:

- результаты наблюдений и
- критерий.

Результаты наблюдений, полученные на выборке, сами по себе, как правило, не используются. Однако на их основе рассчитываются выборочные статистики (показатели), которые непосредственно участвуют в проверке гипотезы.


## Подходы к тестированию статистических гипотез {#stats-testing-approaches}

### Фреквентистский подход {#stats-testing-nhst}

### Байесовский подход {#stats-testing-bayes}

## Возможные результаты проверки гипотез {#stats-testing-results}

В результате проверки статистических гипотез могут возникнуть четыре ситуации.

Мы изучаем в исследовании какую-либо закономерность, которая в реальном мире может существовать, а может и не существовать. В силу неопределённости и вариативности наших данных мы может либо обнаружить интересующую нас закономерность, либо не обнаружить.

В качестве нулевой гипотезы мы выдвигаем предположение о том, что закономерность отсутствует --- так мы упрощаем нашу нулевую гипотезу. Пусть $H_0$ обозначает, что предположение, которое мы проверяем справедливо, а $H_1$ --- не справедливо. На основании данных мы можем либо не отклонить наше предположение ($\hat H_0$), либо отклонить ($\hat H_1$).

Тогда имеем следующую ситуацию:

|            | $H_0$         | $H_1$          |
|:----------:|:-------------:|:--------------:|
| $\hat H_0$ | ✓             | Ошибка II рода |
| $\hat H_1$ | Ошибка I рода | ✓              |

- **Ошибка I рода** возникает, когда в генеральной совокупности _искомой закономерности нет_, но мы в силу случайных флуктуаций в данных _её нашли_.
- **Ошибка II рода** возникает, когда в генеральной совокупности _искомая закономерность есть_, но мы в силу каких-либо причин её _не нашли_.

Ошибки --- это нехорошо, они нас не устраивают. Надо каким-то образом их контролировать.

- **Ошибка I рода** контролируется достаточно просто. Так как мы _нашли_ закономерность, которую искали, мы можем посчитать вероятность, с которой потенциально ошиблись. А собственно контролировать ошибку мы будем с помощью **уровня значимости** $\alpha$, который _выбирается до начала процедуры тестирования гипотезы_. Он и задает вероятность, с который мы позволяем себе ошибиться — отклонить нулевую гипотезу, при условии, что она верна.
- **Ошибку II рода** контролировать сложнее, так как мы _не нашли_ закономерность, которую искали. Нам нужна какая-то метрика, которая позволит сказать, что мы сделали всё возможное для того, чтобы обнаружить искомую закономерность. Вероятность ошибки II рода обозначается $\beta$ --- тогда вероятность того, что мы не совершили ошибку II рода будет $1 - \beta$. Эта величина называется [**статистической мощностью**](#stats-testing-effect-size), и она связана с [_размером эффекта_](#stats-testing-effect-size) и _объемом выборки_. Статистическую мощность можно рассчитать как до проведения статистического анализа  для расчета требуемого объема выборки --- так и после --- для определения достигнутой статистической мощности.

Соберем все обозначения в единую табличку[^cond_prob]:

|            | $H_0$ | $H_1$|
|:----------:|:----------------------------:|:--------------------------:|
| $\hat H_0$ | $\mathrm P (\hat H_0 | H_0)$ | $\mathrm P (\hat H_0 | H_1) = \beta$ |
| $\hat H_1$ | $\mathrm P (\hat H_1 | H_0) = \alpha$ | $\mathrm P (\hat H_1 | H_1) = 1 - \beta$ |

[^cond_prob]: Здесь использовано обозначение условной вероятности $\mathrm P(A|B)$, то есть это вероятность того, что случилось событие $A$ при условии, что случилось событие $B$.

Уровень значимости $\alpha$ **выбирается близким к нулю** --- всем знакомо конвенциональное значение $0.05$. Вообще $\alpha$ можно выбрать сколь угодно малым, однако при выборе уровня значимости руководствуются принципом разумной достаточности, так как если устремить $\alpha$ к нулю, то устремиться к нулю и вероятность отклонения нулевой гипотезы.

<div class="advanced">
<details>
<summary>*Математические руны*</summary>
$$
\mathrm P (\hat H_1) = \mathrm P (\hat H_1 | H_0) \cdot \mathrm P (H_0) = \alpha \cdot \mathrm P(H_0)
$$
</details>
</div>


Достаточной статистической мощностью считается $0.8$. Аналогично, устремляя мощность к единице ($(1 - \beta) \rightarrow 1 \Rightarrow \beta \rightarrow 0$), мы устремляем вероятность не отклонения нулевой гипотезы к нулю:

<div class="advanced">
<details>
<summary>*Ещё математические руны*</summary>
$$
\mathrm P (\hat H_0) = \mathrm P (\hat H_0 | H_1) \cdot \mathrm P (H_1) = \beta \cdot \mathrm P (H_1)
$$
</details>
</div>


Необходимо также помнить, что ошибки первого и второго рода связаны между собой так, что

$$
\alpha \rightarrow 0 \Rightarrow \beta \rightarrow 1
$$


<div class="advanced">
<details>
<summary>*Опять математические руны*</summary>
$$
\beta \cdot \mathrm P (H_1) = \mathrm P (\hat H_0) = \mathrm P (\hat H_0 | H_0) \cdot \mathrm P (H_0) \Rightarrow \beta = \frac{1}{\mathrm P (H_1)} \cdot \mathrm P (H_0) \cdot \mathrm P(\hat H_0 | H_0) \\
\beta = \frac{1}{\mathrm P (H_1)} \cdot \big (1 - \mathrm P (H_1 | H_0)\big) = \frac{1}{\mathrm P (H_1)} \cdot \mathrm P (H_0) \cdot (1 - \alpha)
$$
</details>
</div>


### Асимметрия статистического вывода {#stats-testing-asymmetry}

Выше мы сказали, что для проверки гипотезы нужны две вещи:

* результаты наблюдений и
* критерий.

С результатами наблюдений более-менее очевидно.

**Критерий** --- это правило, согласно которому гипотезу либо принимают, либо отклоняют. Однако перед тем как проверять гипотезу, её так-то нужно сформулировать, и сделать это правильно, поскольку от формулировки гипотезы зависит интерпретация результатов проверки и дальнейшее использование полученной информации.

Используемая статистика сама по себе является [непрерывной] случайной величиной, а значит может быть построено её распределение. Критерий будет разделять это распределение на непересекающиеся области. В результате чего возникает **критическая область** --- область отклонения гипотезы. Дополнением к ней является область неотклонения гипотезы.

Критическая область может быть односторонней (при $H_1:\theta > \theta_0$ или $H_1: \theta < \theta_0$) и двусторонней (при $H_1:\theta \neq \theta_0$). «Размер» критической области определяется **уровнем значимости**.


Статистический вывод — заключение о том, получили ли мы подтверждение альтернативной гипотезы — по структуре представляет собой *импликацию*. Если вам не знаком этот термин из логики, то вот:

* Если значение нашей статистики, которое мы рассчитали на выборке, *попало в критическую область*, то мы говорим о том, что *нулевая гипотеза отклоняется*.
* Если значение нашей статистики, которое мы рассчитали на выборке, *не попало в критическую область*, то мы *не получаем оснований для того, чтобы отклонить нулевую гипотезу*. Однако *мы также не получаем оснований, чтобы её «принять»*. Мы остаёмся в некотором неведении: мы не нашли различий, а есть они там или нет --- хто ж их знает… Итого, мы не можем сделать никакого вывода.

В этом и заключается асимметрия статистического вывода. Как раз для того, чтобы с ней как-то жить, мы работаем со статистической мощностью.

***

Посмотреть, как все эти штуки друг с другом соотносятся можно [тут](https://rpsychologist.com/d3/nhst/).

***


### Связь ошибки первого и второга рода {#stats-testing-errors-connection}


## Агоритм тестирования статистических гипотез {#stats-testing-algorithm}

Для тестирования гипотез есть два сценария: *первый* и *тот, которым мы будем пользоваться*. Первый вариант чуть более классический, второй --- более гибкий.

**Сценарий номер раз**

1. Формулировка гипотезы
2. Выбор статистического критерия
3. Выбор уровня значимости $\alpha$
4. Построение закона распредления статистики критерия при условии, что нулевая гипотеза верна
5. Определение границ критической области
6. Расчёт выборочной статистики
7. Определение, попадает ли наблюдемое значение статистики в критическую область и вынесение решения

**Сценарий номер два**

1. Формулировка гипотезы
2. Выбор статистического критерия
3. Выбор уровня значимости $\alpha$
4. Построение закона распредлеения статистики критерия при условии, что нулевая гипотеза верна
5. Расчёт выборочной статистики
6. Расчёт достигнутого уровня значимости *p-value*
7. Сопоставление $\alpha$ и *p-value* и вынесение решения


Почему второй вариант более гибкий? Представим, что мы захотели понизить уровень значимости с $0.05$ до $0.01$ --- такие уровни значимости всречаются, например, в медицине. Если мы идем по первому сценарию, то нам надо заново пересчитать критические значения и вновь проанализировать, попадает ли наблюдаемое значение в критическую область. Если мы адепты второго сценария, то нам надо только выполнить одно новое сравнение нашего *p-value* с новым уровнем значимости.


## Размер эффекта {#stats-testing-effect-size}


## Статистическая мощность {#stats-testing-power}

::: {.callout-note title="Статистическая мощность Post hoc"}
НАПИСАТЬ

есть ли смысл рассчитывать статистическую мощность пост хок?

кажется, нет, так как эффект уже нашли
:::


## Ложноположительный вывод {#stats-testing-false-positive}

### Проблема множественных сравнений {#stats-testing-multiple-comparisons}

Итак, мы сравниваем попарно все группы наблюдений между собой. В каждом сравнении мы фиксируем вероятность ошибки первого рода с помощью уровня значимости на уровне $0.05$. А какова будет вероятность ошибки, если мы проводим несколько сравнений?

Считаем, что наши сравнения независимы, поэтому вероятности будут перемножаться1. Если верояность ошибиться в одном сравнении равна $\alpha$, то вероятность сделать правильный вывод --- $1 - \alpha$. Тогда вероятность сделать правильный вывод в $m$ сравнениях --- $(1 - \alpha)^m$. Отсюда мы можем вывести вероятность ошибиться хотя бы в одном сравнении:

$$
\prob^′ = 1 - (1 - \alpha)^m
$$
 

Пусть у нас есть три группы, которые нам надо сравнить друг с другом — получается необходимо провести три сравнения. Итого вероятность ошибиться получается:

$$
\prob^′ = 1 - (1 - 0.05)^3 \approx 0.143
$$

Значительно больше, чем $0.05$, что нехорошо. И дальше только хуже. Поэтому нам надо либо корректировать уровень значимости, либо использовать мощные методы типа дисперсионного анализа.

```{r alpha-raise, echo=FALSE}
#| label: alpha-raise
#| fig-cap: "Рост вероятности ошибки первого рода при увеличении числа попарных сравнений"
 
alpha_multiple_comp <- function(n, alpha = .05) {1 - (1 - alpha) ^ n}

tibble(n = 1:10,
       alpha05 = alpha_multiple_comp(n),
       alpha001 = alpha_multiple_comp(n, alpha = .001)) |>
  pivot_longer(cols = -n, names_to = "alpha", values_to = "value") |> 
  ggplot(aes(x = n, y = value, color = alpha)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 1:10) +
  scale_color_discrete(labels = c(alpha05 = "0.05", alpha001 = "0.001")) +
  labs(x = "Number of comparisons",
       y = TeX("$$\\alpha$$"),
       color = "Level of Significance") +
  theme(legend.position = "bottom")
```

#### Корректировка уровня значимости {#stats-testing-correction}

Корректировать уровень значимости можно по-разному. Например, можно разделить $\alpha$ на количество попарных сравнений — такой способ называется поправкой Бонферрони (Bonferroni):

$$
\alpha’ = \frac{\alpha}{n},
$$

где $n$ --- число попарных сравнений.

Поправка Бонферрони считается самой консервативной поправкой — она достаточно сильно уменьшает уровень значимости, и мы можем не поймать искомую закономерность, то есть совершить ошибку второго рода2. Поэтому придумали более либеральные поправки, например, поправку Холма (Холма–Бонферрони, Holm) или поправку Тьюки (Tukey’s HSD test). Можно посмотреть на их формулы, но в целом, не обяз, потому что их все равно никто не знает, а в статистических пакетах мы либо допишем аргумент в функцию, либо нужную галку поставим.

На практике в силу того, что в статистических пакетах мы работаем с p-value, корректируется именно его значение.

По достаточно незамысловатой логике
Здесь: вариант для поправки Бонферрони.

$$
p < \frac{\alpha}{n} \Rightarrow np < \alpha
$$
 
Таким образом, мы просто сравниваем уже скорретированное p-value, которое нам считает программа, с тем же самым $\alpha = 0.05$. Жизнь становится значительно проще и приятнее.



### Проблема количества статистических тестов {#stats-testing-multiple-testing}




