# Оценивание статистических параметров {#stats-estim}
{{< include _symbols.qmd >}}

Мы оказываемся в сложной, но интересной ситуации. Мы хотим знать что-то про генеральную совокупность --- значение некоторого *параметра*. Но мы его никогда не узнаем, потому что не можем работать с целой генеральной совокупностью. Нам остаётся работать только с *выборочной совокупность (выборкой)* и опираться на статистические данные, которые мы собираем на ней.

Выборка извлекается из генеральной совокупности случайным образом, поэтому что там именно --- с точки зрения данных --- в нашей выборке будет нам также неизвестно. Отсюда происходят два ключевых свойства статистических данных --- *неопредлённость* и *вариативность*.

**Неопределённость** нам говорит о том, что мы не знаем, что именно мы получим в результате наших измерений для конкретной выборки. В том числе потому, что мы работаем на просторах случайных величин.

**Вариативность** означает, что наши данные будут различатся ещё и от респондента к респонденту. И между выборками тоже. Здесь и ошибка измерения, и различные смешения и ещё куча всего.

В итоге что мы имеем: так как нам не доступны *истинные* значения параметров, придётся использовать *оценки* этих параметров.



## Точечные оценки
::: {.lab-chapter .lab-junior}
:::

Параметр обычно обозначается греческой буквой. Пусть у нас есть некоторый параметр генеральной совокупности $\theta$. Его аналогом на выборочной совокупности является его *точечная оценка* $\hat \theta$. Точечная она, потому что представляет собой некоторое одно число. Таким образом, это наиболее компактный способ составить представление о значении параметра. По своей сути она, на самом деле, она является функцией от результатов наблюдений:

$$
\hat \theta = \hat \theta (x), \; x = (x_1, x_2, \dots, x_n)
$$

Что это значит? То, что на разных выборках эта оценка может различаться. Возьмем для примера такой параметр как среднее значение. Предположим, что мы исследуем интеллект, и наша *генеральная совокупность* представлена таким набором наблюдений:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())
```

```{r, echo=FALSE}
iq <- tibble(id = 1:10000, IQ = round(rnorm(10000, 100, 15)))
```

```{r}
nrow(iq)
head(iq)
tail(iq)
```

Так как мы предположили, что это генеральная совокупность, то мы можем посчитать истинное значение параметра $\mu$. **В реальной жизни мы этого сделать не можем!**

```{r}
mean(iq$IQ)
```

Вполне ожидаемое значение[^1]. Теперь попробуем наизвлекать выборок человек по 50 и посчитать *оценки среднего (выборочные средние)* $\hat \mu$ на них:

```{r}
means <- numeric()
for (i in 1:100) {
  means[i] <- mean(sample(iq$IQ, 50, replace = FALSE))
}
ggplot(NULL, aes(means)) +
  geom_histogram(binwidth = 1, fill = 'royalblue4', color = 'lightgray') +
  geom_vline(xintercept = mean(iq$IQ)) +
  labs(x = 'Выборочные средние IQ',
       y = 'Количество')
```

Наблюдаем, что иногда мы при подсчёте оценке параметра попадаем близко к истинному его значению, иногда промахиваемся. Собственно, как раз об этом *неопределённость и вариация*.

### Метод моментов
::: {.lab-chapter .lab-junior}
:::

Чтобы получить точечные оценки параметров, используются разные методы в зависимости от конкретной модели анализа. Сейчас мы познакомимся с самым простым --- **методом моментов**.

Само название метода отсылает нас к обсуждению [характеристик распределений случайных величин](#moments_distributions). Мы говорили о том, что распредления характеризуются их *моментами*. В методе моментов есть три этапа:

1) устанавливается связь между оцениваемым параметром и моментом распределения

$$
\theta = \xi(\nu_k) \quad \text{или} \quad \theta = \xi(\mu_k)
$$

2) находятся выборочные моменты

$$
\hat \theta = \xi(\nu_k^*) \quad \text{или} \quad \hat \theta = \xi(\mu_k^*)
$$

3) истинный момент заменяется на выборочный --- получается оценка.

Для примера разберём всё тот же датасет с IQ. Мы знаем, что распределение баллов IQ подчинается [нормальному закону](#normal_distribution). Поэтому в качестве параметра «среднее значение коэффициента интеллекта» генеральной совокупности можно использовать математическое ожидание:

$$
\mu = \mathbb{E}X
$$

Выборочным аналогом математического ожидания является выборочное среднее:

$$
\hat \mu = \frac{1}{n} \sum_{i=1}^n x_i
$$

И это, собственно, всё. Если вы хотя бы раз анализировали данные, вы имплицитно пользовались этим знанием. Просто, скорее всего, не задумывались, что это так работает. :)


### Метод максимального правдоподобия
::: {.lab-chapter .lab-middle}
:::

### Bootstrap
::: {.lab-chapter .lab-middle}
:::

### Свойства точечных оценок
::: {.lab-chapter .lab-middle}
:::

Так как точечные оценки всё же оценки, мы можем и промахнуться мимо истинного среднего --- это мы наблюдали на гистограмме. Поэтому нам надо предъявить определённые требования к точечным оценкам. Их три: *несмещённость*, *состоятельность* и *эффективность*.

#### Несмещенность
::: {.lab-chapter .lab-middle}
:::

**Несмещённость** выражает следующую идею: когда мы рассчитываем выборочную оценку, мы должны как можно ближе попадать в истинное значение параметра.

$$
\forall n \; \mathbb{E} \hat \theta = \theta, \quad (\mathbb{E}\hat \theta - \theta) \rightarrow 0,
$$
где $n$ --- объём выборки, $(\mathbb{E}\hat \theta - \theta)$ --- смещение.

Слева представлено требование *несмещённости при любом объёме выборки*, а справа --- *ассимптотической несмещённости*.


##### Проверка среднего как оценки математического ожидания на несмещенность

$$ 
X_1, X_2, \dots , X_n \overset{\iid}{\thicksim} (\mu, \sigma^2)
$$

$$
\hat \mu = \frac{1}{m}\sum_{j=1}^m x_j = \bar X 
$$

$$
\expect (\hat \mu) = \expect (\bar X) \overset{?}{=} \mu
$$

$$
\expect (\bar X) = \expect \big (\frac{1}{n} \sum_{i=1}^n X_i \big ) = \frac{1}{n} \expect \Big( \sum_{i=1}^n X_i \Big) = \frac{1}{n} \sum_{i=1}^n \expect X_i \overset{X_i \overset{\iid}{\sim} (\mu, \sigma^2)}{=} \frac{1}{n} \cdot n \cdot \expect X = \frac{n}{n} \cdot \mu = \mu
$$



##### Проверка дисперсии генеральной совокупности как оценки дисперсии на несмещенность

$$ 
X_1, X_2, \dots , X_n \overset{\iid}{\thicksim} (\mu, \sigma^2)
$$

$$
\begin{split}
\disp X & = \sigma^2 = \expect(X - \expect X)^2 = \expect (X^2 - 2 X \expect X + \expect^2 X) = \\
& = \expect X^2 - 2\expect X \expect X + \expect^2 X = \expect X^2 - 2\expect^2 X + \expect^2 X = \\
& = \expect X^2 - \expect^2 X
\end{split}
$$

$$
\hat \sigma^2 = \frac{\sum_{i=1}^n (x_i - \bar X)^2}{n}
$$

$$
\expect (\hat \sigma^2) \overset{?}{=} \sigma^2
$$

$$
\begin{split}
\expect (\hat \sigma^2) & = \frac{\sum_{i=1}^n (x_i - \bar X)^2}{n} = \\
& = \frac{1}{n} \lp \sum_{i=1}^n x_i^2 - 2 \sum_{i=1}^n x_i \bar X  + \sum_{i=1}^n \bar X \rp \\ 
& = \frac{1}{n} \lp \sum_{i=1}^n x_i^2 - 2 \bar X \sum_{i=1}^n x_i + n \bar X \rp = \\
& = \frac{\sum_{i=1}^n x_i^2}{n} - 2 \bar X \frac{\sum_{i=1}^n x_i}{n} + \bar X^2 = \\
& = \overline{X^2} - 2 \bar X^2 + \bar X^2 = \overline{X^2} - \bar X^2
\end{split}
$$

$$
\expect (\hat \sigma^2) = \expect (\overline {X^2} - \bar X^2) = \underset{[1]}{\expect \overline{X^2}} - \underset{[2]}{\expect \bar X^2}
$$

$$
\begin{split}
[1] \, \expect \overline{X^2} : & \\

\expect \overline{X^2} & = \expect \lp \frac{\sum_{i=1}^n X_i^2}{n} \rp = \frac{1}{n} \expect \lp \sum_{i=1}^n X_i^2 \rp = \\
& = \frac{1}{n} \sum_{i=1}^n \expect X_i^2] \overset{X_i \overset{\iid}{\sim} (\mu, \sigma^2)}{=} \frac{1}{n} \cdot n \cdot \expect X^2 = \expect X^2

\end{split}
$$

$$
\begin{split}
[2] \, \expect \bar X^2 : & \\

\expect \bar X^2 & = 
\expect \lb 
    \lp \frac{\sum_{i=1}^n X_i}{n} \rp ^2 
  \rb = 
\frac{1}{n^2} 
\expect \lb 
    \lp \sum_{i=1}^n X_i^2 \rp 
  \rb = \\
& = \frac{1}{n^2} \expect \lb 
    \sum_{i=1}^n \expect X_i^2 + 
    2 \sum_{
      \substack{i=1, j=1 \\ i \neq j}
      }^n X_i X_j 
    \rb = \\
& = \frac{1}{n^2} \lb
      \sum_{i=1}^n \expect (X_i^2) + 
      2 \sum_{
        \substack{i=1, j=1 \\ i \neq j}
      }^n \expect (X_i X_j)
    \rb = \\
& \overset{X_i \overset{\iid}{\sim} (\mu, \sigma^2)}{=} \frac{1}{n^2} \lb 
    n \cdot \expect X^2 + 
    2 \sum_{
      \substack{i=1, j=1 \\ i \neq j}
    }^n \expect (X_i) \expect (X_j) \rb = \\
& = \frac{1}{n} \lb n \cdot \expect X2 + 2 \cdot \frac{n(n-1)}{2} \expect^2 X \rb  = \\
& = \frac{1}{n} \expect X^2 + \frac{n-1}{n} \expect^2 X
\end{split}
$$

$$
\begin{split}
\expect (\hat \sigma^2) 
& = \expect \overline{X^2} - \expect \bar X^2 = \\
& = \expect X^2 - \lp \frac{1}{n} \expect X^2 + \frac{n-1}{n} \expect^2 X \rp = \\
& = \frac{n}{n} \expect X^2 - \frac{1}{n} \expect X^2 - \frac{n-1}{n} \expect^2 X = \\
& = \frac{n-1}{n} \expect X^2 - \frac{n-1}{n} \expect^2 X = \frac{n-1}{n} \lp \expect X^2 - \expect ^2 X \rp \\ 
& = \frac{n-1}{n} \sigma^2
\end{split}
$$

$$
s^2 = \frac{n}{n-1} \sigma^2 = \frac{n}{n-1} \cdot \frac{1}{n} \cdot \sum_{i=1}^n (x_i - \bar X) = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar X)
$$



#### Состоятельность
::: {.lab-chapter .lab-middle}
:::

Математически **состоятельность** определяется следующим образом:

$$
\lim_{n \rightarrow \infty} \prob (|\hat \theta - \theta| < \varepsilon) = 1, \, \varepsilon > 0
$$

Содержательно эта запись нам говорит следующее, что при неограниченном росте мощности выборки наша оценка стремится к истинному значению параметра. Может быть, такая формулировка не совсем точна математически, но позволяет представить, что происходит. 


#### Эффективность
::: {.lab-chapter .lab-middle}
:::

Эффективность точечной оценки определяется достаточно просто. Так как оценка параметра --- это случайная величина, но у неё есть *дисперсия*. Чтобы оценка была **эффективна**, её дисперсия должна быть минимальной:

$$
\sigma^2_{\hat \theta} = \min
$$

Пример несмещённой, состоятельной и эффективной оценки --- это выборочное среднее для оценки математического ожидания нормально распределённой величины. Именно то, что мы и делали в примере применения метода моментов.



## Интервальные оценки
::: {.lab-chapter .lab-junior}
:::

Кроме самого значения оценки, необходимо определить качество этой оценки, иначе говоря --- её точность. Для этого используется такая величина как **надёжность**:

$$
\gamma = \mathrm{P}(\theta_\min < \theta < \theta_\max)
$$

Такая форма оценки называется **интервальной оценкой параметра**, так как мы указываем *интервал*, в котором находится истинное значение с определённой вероятностью.

Такая форма оценки даёт исчерпывающую информацию о параметре: мы знаем (1) интервал, в котором находится значение параметра генеральной совокупности, а также (2) надёжность, с которой выбранный интервал накрывает это значение.

Значение надежности $\gamma$ может быть выбрано произвольно, но обычно оно близко к единице. Однако необхожимо помнить, что чем выше надёжность, тем шире границы интервальной оценки.



### Стандартная ошибка
::: {.lab-chapter .lab-junior}
:::


#### Почему $\se(X) = \frac{\sd(X)}{\sqrt{n}}$
::: {.lab-chapter .lab-senior}
:::

$$
\var (X + Y) = \var (X) + \var(Y) + 2 \cov (X, Y)
$$

$$
\var (aX) = a^2 \var (X)
$$

Так как наблюдения извлекаются из независимых одинаково распределенных величин (independent identically distributed, iid), то

$$
\cov (X_i, X_j) = 0, \sigma_{X_i} = \sigma_{X_j} = \sigma
$$

$$
\var \Big( \frac{1}{n} \sum X_i \Big) = \frac{1}{n^2} \sum \var(X_i) = \frac{1}{n^2} \sum \sigma^2 = \frac{n}{n^2} \sigma^2 = \frac{\sigma^2}{n}
$$

$$
\se_X = \sqrt{ \var \Big( \frac{1}{n} \sum X_i \Big)} = \sqrt{\frac{\sigma^2}{n}} = \frac{\sigma}{\sqrt{n}}
$$


### Доверительный интервал
::: {.lab-chapter .lab-junior}
:::

Вариантом интервальной оценки является **доверительный интервал (confidence interval)**. Итак, ещё раз:

$$
\mathrm{P}(\theta_\min < \theta < \theta_\max) = \gamma, \; \gamma \rightarrow 1
$$

$theta_\min$ и $\theta_\max$ --- границы доверительного интервала, $\gamma$ --- доверительная вероятность. На практике её значение чаще всего принимается равным $0.95$.

**Алгоритм определения интервальной оценки** следующий:

1) Найсти статистику $\zeta(\theta)$, связанную с оцениваниемым параметром, закон распределения которой известен $f(\zeta)$.
2) Определить значения $\zeta_\min$ и $\zeta_\max$, в пределах которых статистика находится с вероятностью $\gamma$.
3) Зная связь $\zeta(\theta)$ перейти к границам $\theta_\min$ и $\theta_\max$.

Разберемся с этим на примере построения доверительного интервала для генерального среднего.

Первая задача --- найти статистику. Мы воспользуемся тем, что за нас поработали учёные-статистики и сказали, что вот такая вполне подойдёт:

$$
t = \frac{\bar x - \mu}{s}\sqrt{n-1},
$$

где $t$ --- значение статистики, $\bar x$ --- выборочное среднее, $\mu$ --- генеральное среднее, $s$ --- выборочное стандартное отклонение, $n$ --- объём выборки.

Известен ли закон её распредления? Да. Эта статистика подчинается $t$-распределению (распределению Стьюдента). Оно похоже на нормальное, но хвосты у него повыше:

<center>
<img src="img/student_pdf.jpg">
</center>

Теперь надо сформулировать вид интервальной оценки для генерального среднего. Путем арифметических преобразований формулы выше мы имеет следующее:

$$
\mu = \bar x - t \frac{s}{\sqrt{n-1}}
$$

Значит вид интервальной оценки будет таков:

$$
\mathrm{P}\Big( \bar x - t_\alpha \frac{s}{\sqrt{n-1}} < \mu < 
\bar x + t_\alpha \frac{s}{\sqrt{n-1}}\Big) = 1 - \alpha = \gamma
$$

Посмотрим на картинку:

<center>
<img src="img/mean_ci_graph.jpeg">
</center>

Видим на ней наш доверительный интвервал и значения $t_\alpha$ и $-t_\alpha$. Сама $\alpha$ обозначает вероятность выхода за границы доверительного интервала. Осталось всё это высчитать в числах, и получить границы доверительного интервала.

Хорошо, что весь этот ужас в R скрыт под капотом:

```{r, message=FALSE}
mean_cl_normal(iq$IQ)
mean_cl_boot(iq$IQ)
```

[^1]: Шкала IQ устроена так, что её среднее значение равно 100, а стандартное отклонение 15.

