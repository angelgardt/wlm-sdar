# Вероятность как математическая конструкция {#prob}

{{< include other/_symbols.qmd >}}

```{r opts, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE}
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, error=FALSE)
```

```{r pkgs}
library(tidyverse)
theme_set(theme_bw())
```


:::{.intro}
Озадачимся более серьезно построением «вероятности» с опорой на фундамент всей современной математики --- теорию множеств.
:::


## Эксперименты со случайным исходом {#prob-randexp}

:::{.lab-senior}
:::

Вернемся к концепции **эксперимента со случайным исходом (случайного эксперимента)**, который как мы выяснили ранее(HREF), происходит каждый раз в момент измерения. Нам необходима некая математическая модель такого эксперимента, чтобы мы могли далее с этим феноменом работать.

Математическая модель случайного эксперимента содержит несколько требований:

1. **Недетерминированность исхода** <br> 
Мы не можем знать наверняка, что произойдет в конкретном эксперименте. В этом смысле бросание теннисного мяса с заданной высоты не является случайным экспериментом, так как исход абсолютно точно известен заранее --- мяч совершит движение вертикально вниз и ударится оземь.
1. **Принципиальная возможность повторения эксперимента** (во времени и/или в пространстве) <br>
Мы можем повторить наш эксперимент сколь угодно большое количество раз. Причем эти повторения могут быть разнесены друг от друга во времени (100 раз подряд подбросить одну и ту же монетку) или в пространстве (одновременно подбросить 100 монеток). В этом смысле сдача экзамена некоторым студентом не является случайным экспериментом --- студент сдает экзамен [в идеале] один раз[^exam-times].
1. **Неизменность условий эксперимента** <br>
Во всех повторениях эксперимента условия его проведения не изменяются. В этом смысле даже если рассмотреть ситуацию трёхкратной сдачи экзамена некоторым студентом, она не является случайным экспериментом, так как студент [наверное, хотелось бы думать, что] готовится к пересдачам, соответственно, условия сдачи экзамена меняются.
1. **В одном повторении эксперимента некий исход может либо реализовать, либо не реализоваться** <br>
Данное требование позволяет ввести такую характеристику исхода случайного эксперимента как *частота*. <br>
Исход $A$ имеет [относительную] частоту $\displaystyle \frac{n(A)}{n}$, если в $n$ повторениях случайного эксперимента этот исход реализовался $n(A)$ раз.
1. **Статистическая устойчивость частоты** <br>
Под этим понимают две вещи:
    - с ростом числа повторений случайного эксперимента относительная частота события $A$ должна приближаться к некоторому значению [@serdobolskaya2019] (@fig-prob-stat-stability-1)
    - в разных сериях случайных экспериментов относительная частота события $A$ (при достаточно большом количестве повторений случайного эксперимента) не должна сильно меняться [@erlikh2019] (@fig-prob-stat-stability-2).

[^exam-times]: Окей, максимум --- три. Этого всё равно не достаточно для выполнения данного требования.

```{r prob-stat-stability-plots}
set.seed(123)

tibble(n = seq(1, 5000, by = 5),
       p = n %>% 
  map(sample, x = 1:6, replace = TRUE) %>% 
  map(table) %>% 
  map(.[1]) %>% 
  unlist() %>% 
  `/`(n)
  ) %>% 
  ggplot(aes(n, p)) +
  geom_point(size = 1) +
  geom_hline(yintercept = 1/6,
             color = "#9AEBC6",
             linewidth = 1) +
  ylim(0, 1) +
  labs(x = "Количество случайных экспериментов",
       y = "Относительная частота") -> plot1


set.seed(956)
sample(1:6, 500*1000, replace = TRUE) %>% 
  matrix(ncol = 1000) %>% 
  apply(2, function(x) sum(x == 1)) %>% 
  `/`(500) %>% 
  tibble(n = 1:1000,
         p = .) %>% 
  ggplot(aes(x = n,
             y = p)) +
  geom_point(size = 1) +
  geom_hline(yintercept = 1/6,
             color = "#36D38C",
             linewidth = 1) +
  ylim(0, 1) +
  labs(x = "Номер серии экспериментов",
       y = "Относительная частота") -> plot2
```

```{r prob-stat-stability-fig}
#| label: fig-prob-stat-stability
#| fig-cap: "Статистическая устойчивость"
#| fig-subcap:
#|   - "С ростом числа испытания относительная частота приближается к некоторому значению"
#|   - "В разных сериях испытаний относительная частота примерно постоянна"
#| layout-ncol: 2

print(plot1)
print(plot2)
```


Значение, в которому стремится относительная частота исхода случайного эксперимента, естественно назвать *вероятностью этого исхода*:

$$
\prob (A) \approx \frac{n(A)}{n}, \, n \to \infty
$$

Окей... Но ведь мы это же самое говорили, когда рассматривали статистическую интерпретацию вероятности! В чем здесь проблема?


### Несостоятельность $\prob (A) \approx \frac{n(A)}{n}$ как определения вероятности {#prob-not-freq}

:::{.lab-senior}
:::

Если мы внимательно присмотримся к записи $\displaystyle \prob (A) \approx \frac{n(A)}{n}, \, n \to \infty$, то обнаружим, что в качестве математического определения вероятности она совершенно не годится [@serdobolskaya2019].

* Во-первых, его невозможно [эмпирически] проверить --- необходимо бесконечно время ($n \to \infty$), а значит, изменятся условия эксперимента и не будет выполнено соответствующее требование модели случайного эксперимента.
* Во-вторых, математика не очень любит приближённые равенства. Можно было бы выкрутиться пределом, и сказать, что $\displaystyle \prob (A) = \lim_{n \to \infty} \frac{n(A)}{n}$), но это нас на спасёт. Здесь слева от знака равенства стоит число $\prob (A)$, а частное $\displaystyle  \frac{n(A)}{n}$ под знаком предела --- *случайное* число, поскольку случаен и сам исход $A$. В каком-то смысле относительная частота ещё более случайная, чем исход $A$, так как исход может либо реализоваться, либо нет, а частота может принимать любое значение от $0$ до $1$ c шагом $\displaystyle \frac{1}{n}$.
    * Тогда необходимо определить предел последовательности случайных чисел! Но и здесь возникает проблема --- разность между вероятность и частотой также случайна, поэтому определить предел аналогично тому, как это делается в математическом анализе, не получится.
* Однако есть другая проблема --- «концептуальная» --- равенство $\displaystyle \prob (A) = \lim_{n \to \infty} \frac{n(A)}{n}$ зациклено само на себе. Мы пытаемся определить вероятность, используя частоту, но поведение частоты в случайном эксперименте определяется тем, как задана вероятность в той или иной математической модели.

Таким образом, это выражение не может быть математическим определением, однако оно может быть теоремой теории вероятности, которую мы в виде приближенного равенства сможем использовать в эмпирической проверке расчётов. Для вычисления же самой вероятности необходимо построить математическую конструкцию вероятности. Решением этой задачи и занимается теория вероятности.


## Элементарные исходы и события {#prob-events}
:::{.lab-senior}
:::

Определимся концептуально, что **вероятность --- это мера множества**. **Мера** --- это правильно, которое приписывает множеству *числовое значение*. Мерой как математической конструкцией занимается теория меры(HREF), однако можно найти и хорошо знакомых нам из практики представителей меры --- это, например, длина, площадь, объем или масса. Вероятность является ещё одной мерой, правда, найти ей осязаемый физический аналог оказывается сложнее.

Тем не менее, мы обозначили, что есть некоторое множество, для которого вероятность является мерой. Надо разобраться в том, что это такое за множество.

Пусть есть некоторый эксперимент со случайным исходом. Мы знаем, что в рамках этого эксперимента может произойти, но на можем сказать, что именно произойдет в конкретном случайном эксперименте. Обозначим каждый из возможных исходов [в одном повторении случайного эксперимента] как $\omega$ и назовём **элементарным исходом**[^elem-event].

[^elem-event]: Также встречается термин «элементарное событие».

Если мы соберем все возможные элементарные исходы случайного эксперимента в мешок, то получим **множество элементарных исходов**[^Omega], обозначаемое $\Omega$.

[^Omega]: Также используется термин «пространство элементарных исходов (событий)», однако он в данном случае не совсем корректен. В математике термин «пространство» подразумевает, что между элементами есть какие-либо отношения, однако никаких отношений между элементарными исходами во множестве элементарных исходов нет. Это буквально мешок, в который собрали все элементарных исходы какого-то конкретного случайного эксперимента.

Приведем примеры множеств элементарных исходов. Начнем с чего-то суперклассического. Рассмотрим следующий случайный эксперимент: «один раз брошена монета». Тогда 

$$
\Omega = \{ \omega_1, \omega_2 \},
$$

где $\omega_1$ --- «монета упада “орлом” вверх», $\omega_2$ --- «монета упала “решкой” вверх». Множество элементарных исходов в этой случае состоит всего из двух элементов.

Другой пример: «один раз брошен игральный кубик». В этом случае множество элементарных исходов состоит из шести элементов:

$$
\Omega = \{ \omega_1, \omega_2, \omega_3, \omega_4, \omega_5, \omega_6 \},
$${#eq-dice-omega}

где 

* $\omega_1$ --- «выпала грань с одной точкой», 
* $\omega_2$ --- «выпала грань с двумя точками»,
* $\omega_3$ --- «выпала грань с тремя точками», 
* $\omega_4$ --- «выпала грань с четырьмя точками», 
* $\omega_5$ --- «выпала грань с пятью точками», 
* $\omega_6$ --- «выпала грань с шестью точками».

:::{.callout-note}
###### Модель vs реальность

Конечно, множество элементарных исходов --- это *модель*, и как и в любой модели, в ней присутствует ряд упрощений. Так, не рассматриваются события, «монета упала на ребро» или «игральный кубик упал на ребро», а события «монета упала на стол “орлом” вверх» и «монета упала на пол “орлом” вверх» считаются один и тем же событием. Однако мы пользуемся такими моделями для описания реальных экспериментов, если подобные идеализации, во-первых, адекватно, а во-вторых, вполне хорошо приближают реальность.

:::

Приведем ещё примеры множеств элементарных исходов, более близким к психологии. Случайный эксперимент: «респондент отвечает на вопрос опросника, используя пятибалльную шкалу Ликерта». Тогда

$$
\Omega = \{ \omega_1, \omega_2, \omega_3, \omega_4, \omega_5 \},
$$

где 

* $\omega_1$ --- «респондент выбрал ответ <1>», 
* $\omega_2$ --- «респондент выбрал ответ <2>»,
* $\omega_3$ --- «респондент выбрал ответ <3>», 
* $\omega_4$ --- «респондент выбрал ответ <4>», 
* $\omega_5$ --- «респондент выбрал ответ <5>».

Случайный эксперимент: «респондент заполняет опросник STAI»[^STAI]. Тогда множество элементарных исходов будет таким:

[^STAI]: Шкала тревоги Спилбергера-Ханина (State-Trait Anxiety Inventory, STAI) [@khanin1976; @zaytsev2011]

$$
\Omega = \{ (\omega_{1i}, \omega_{2j}) \such 20 \leq i,j \leq 80\},
$${#eq-stai-omega}

где $\omega_{1i}$ --- «респондент набрал $i$ баллов по шкале ситуативной тревожности», $\omega_{2}$ --- «респондент набрал $j$ баллов по шкале личностной тревожности».

Случайный эксперимент: «неподготовленный студент решает тест по курсу “Психодиагностика и основы психометрики” из 30 заданий, каждое из которые оценивается дихотомически». Тогда множество элементарных исходов для балла за тест будет следующим:

$$
\Omega = \{ \omega_{i} \such 0 \leq i \leq 30 \},
$${#eq-psydiag-omega}

где $\omega_{i}$ --- «студент набрал $i$ баллов за тест».

И так далее. Для каждого случайного эксперимента мы можем описать множество элементарных исходов.

Однако сами элементарные исходы на часто не очень интересуют. Интереснее рассматривать «неэлементарные» исходы, так как они будут соответствовать более содержательным вопросам. Так, например, если считать, что тест по «Психодиагностике и основам психометрики» сдан, если студент набрал не менее 20 баллов, то логично интересоваться событием $A$ «тест сдан», которые состоит из следующих элементарных исходов из $\Omega$ (@eq-psydiag-omega):

$$
A = \{ \omega_{i} \such 20 \leq i \leq 30 \}
$$

Или же рассмотреть событие $A$ «у респондента низкая ситуативная и личностная тревожность» (@eq-stai-omega):

$$
A = \{ (\omega_{1i}, \omega_{2j}) \such 20 \leq i,j \leq 30\}
$$

Ну, или же вернуться к истокам, и изучить событие «на игральной кости выпало четное число очков» (@eq-dice-omega):

$$
A = \{ \omega_2, \omega_4, \omega_6 \}
$$

Таким образом, когда мы говорим о «неэлементарных» события, которые далее будем называться просто **событиями**, мы рассматриваем подмножества $A \subseteq \Omega$.

Получается, что **вероятность --- это мера множества элементарных исходов**.

:::{.callout-note}
###### Элементарные исходы, множество элементарных исходов, события

Итак, зафиксируем введенные обозначения и термины.

* В случайном эксперименте может реализоваться некоторое количество **элементарных исходов** $\omega$.
* Все элементарные исходы составляют **множество элементарных исходов** $\Omega$:

$$
\Omega = \{ \omega_1, \omega_2, \ldots, \omega_n, \ldots \}
$$

* **Любое событие** $A$ является подмножеством множества элементарных исходов $\Omega$:

$$
A \subseteq \Omega
$$

:::


### Как может быть устроено $\Omega$? {#prob-omega-types}

:::{.lab-senior}
:::

Выше мы рассматривали примеры множеств элементарных исходов с конечным числом элементов. Здесь все достаточно понятно. А может ли число элементарных исходов быть бесконечным?

Да, по крайней мере, в математической модели. Например, следующий случайный эксперимент: «монету бросают до первого выпадения “орла”». Тогда множество элементарных исходов примет следующий вид:

$$
\Omega = \{\omega_1, \omega_2, \ldots, \omega_n, \ldots\},
$$

где 

* $\omega_1 = \text{H}$,
* $\omega_1 = \text{TH}$,
* $\vdots$
* $\omega_n = \underbrace{\text{T..T}}_{n-1}\text{H}$,
* $\text{H}$ --- «орёл» («head»), $\text{T}$ --- «решка» («tail»).

В этом случае множество элементарных исходов $\Omega$ равномощно множеству натуральных чисел $\setN$ --- $|\Omega| = |\setN|$--- то есть является *счётным*. Такие множество элементарных исходов встречаются в психологических исследованиях примерно никогда, поэтому на них останавливаться мы не будем, но будем иметь их в виду.

Также в математике есть множества, которые *не являются конечными*, и *не являются счетными*. Они тоже используются в математических моделях случайных экспериментов. Например, ситуация измерения температуры. Пусть мы решили измерить температуру за окном в июле. Множество элементарных исходов такого случайного эксперимента будет описываться так:

$$
\Omega = [T_\min, T_\max],
$$

где $T_\min = 15^\circ \text{C}$, $T_\max = 35^\circ \text{C}$. При этом температура может быть абсолютно любым значением из заданного диапазона.

Приведем пример из области психологии. Пусть у нас есть эксперимент, в котором измеряется время реакции (скажем, задача лексического решения). Тогда зададим множество элементарных исходов так:

$$
\Omega = [t_\min, t_\max],
$$

где, скажем, $t_\min = 0.3 \, \text{c}$, $t_\max = 1.5 \,\text{c}$. При этом время реакции может быть абсолютно любым значением из заданного диапазона. О границах диапазона можно поразмышлять, но в данном случае это не очень существенно, важно, что внутри границ содержится бесконечно много значений, причем эта бесконечность больше, чем количество натуральных чисел $|\setN|$.

Таким образом, если мы хотим описать эксперимент с помощью $\Omega$, нам надо иметь в виду, что это множество может быть абсолютно любой природы с точки зрения количества элементов. Это сделает нам некоторые проблемы, но о них позже.


### Операции над событиями {#prop-events-operations}

:::{.lab-senior}
:::

Напомним себе, что мы пытаемся построить конструкцию вероятности, и дошли до того, что определили события как подмножества множества элементарных исходов. Чтобы далее работать с событиями, нам нужны какие-то операции над нами. Вполне естественно, раз уж мы заговорили о множествах, чтобы операции над событиями отражали операции над множествами. Ниже представлены эти соотношения (@tbl-evets-set).

::: {#tbl-evets-set}

|                                 События                                	|                                                                         Множества                                                                        	|
|:----------------------------------------------------------------------:	|:--------------------------------------------------------------------------------------------------------------------------------------------------------:	|
|                       $\omega$ влечёт событие $A$                      	|                                                                    $$ \omega \in A $$                                                                    	|
|     Событие $A$ состоит из элементарных исходов, которые влекут $A$    	|                                          $$ \omega \in A \vee \omega \not \in A \, \forall \omega \in \Omega $$                                          	|
| Событие $A$ влечёт событие $B$ («если $A$, то $B$», $A \Rightarrow B$) 	|                                          $$ A \subseteq B \Leftrightarrow \forall \omega \in A, \omega \in B $$                                          	|
|                 Событие $A$ не произошло: $\overline A$                	|                              Дополнение к множеству $A$ $$ \overline A = \{ \omega \in \Omega \such \omega \not \in A \} $$                              	|
|          Произошли все события $A_i$ в одном акте эксперимента         	|                       Пересечение множеств $A_i$ $$ \bigcap_i A_i = \{ \omega \in \Omega \such \forall i \,\, \omega \in A_i \} $$                       	|
|                 Произошло хотя бы одно событие из $A_i$                	|                          Объединение множеств $$ \bigcup_i A_i = \{ \omega \in \Omega \such \exists i \,\, \omega \in A_i \} $$                          	|
|           Произошло событие $A$, но не произошло событие $B$           	|                        Разность множеств $$ A \setminus B = \{ \omega \in \Omega \such \omega \in A \wedge \omega \not \in B \} $$                       	|
|         Либо произошло событие $A$, либо произошло событие $B$         	| Симметрическая разность множеств $$ A \symdif B = \{ \omega \in \Omega \such \omega \in A \xor \omega \not \in B \} = (A \cup B) \setminus (A \cap B) $$ 	|

Соотношение событий и операций над множествами

:::

:::{.callout-tip}
### Свойства операций над множествами

Вспомним кратко свойства операций над множествами, чтобы не листать книжку.

1. Коммутативность <br> $A \cup B = B \cup A$ <br> $A \cap B = B \cap A$
2. Ассоциативность <br> $(A \cup B) \cup C = A \cup (B \cup C)$ <br> $(A \cap B) \cap C = A \cap (B \cap C)$
3. Дистрибутивность <br> $(A \cup B) \cap C = (A \cap C) \cup (A \cap B)$ <br> $(A \cap B) \cup C = (A \cup C) \cap (A \cup B)$
4. Формулы двойственности <br> $\overline{A \cap B} = \overline A \cup \overline B$ ; $\overline{A \cup B} = \overline A \cap \overline B$ <br> $\displaystyle \overline{\bigcup_i A_i} = \bigcap_i \overline{A_i}$; $\displaystyle \overline{\bigcap_i A_i} = \bigcup_i \overline{A_i}$
5. Свойства включения <br> $A \subseteq B \wedge B \subseteq C \Rightarrow A \subseteq C$ <br> $\emptyset \subset A \subset \Omega$ <br> $A \subset B \Rightarrow \cases{A \cap B = A \\ A \cup B = B}$
6. Двойное дополнение <br> $\overline{(\overline A)} = A$

:::


## Предел последовательности множеств {#prob-lim-set}

:::{.lab-senior}
:::

Мы движемся всё ещё движемся к построению вероятности, однако давайте на секунду остановимся и задумаемся вот на чем: когда мы построим вероятность, нам необходимо будет исследовать её аналитические свойства, чтобы понять, как она работает. Исследование любых аналитических свойств предполагает, что мы умеем считать пределы последовательностей. Так как вероятность будет стоять на множествах --- в частности, событиях --- нам потребуются пределы последовательностей множеств. На данный момент совершенно не ясно, как их считать. Озаботимся этим вопросом.

Сходу неясно, как посчитать предел последовательности множеств, но из матана мы знаем, как считать предела числовых последовательностей. Можно ли как-то на элементах множеств создать некоторую числовую последовательность, логически отражающую свойства множеств?


### Индикаторная функция {#prob-indic-function}

:::{.lab-guru}
:::

Да. Сделаем мы это исходя из весьма простого соображения.

:::{#def-indic-funciton}
Функция $\chi_A(\omega): \Omega \to \{0, 1\}$ называется **индикаторной функцией множества $A$**, если она задана следующим образом:

$$
\chi_A(\omega) = \cases{
1, \, \omega \in A \\
0, \, \omega \not \in A
}
$$

:::

Будет ли такая функция отражать свойства множеств? Да, так как она обладает следующими свойствами:


1. $A \subseteq B \Leftrightarrow \chi_A(\omega) \leq \chi_B(\omega), \, \forall \omega \in \Omega$
2. $A = B \Leftrightarrow \chi_A(\omega) = \chi_B(\omega), \, \forall \omega \in \Omega$
3. $\chi_{\overline A} (\omega) = 1 - \chi_A(\omega), \, \forall \omega \in \Omega$
4. $\chi_{A \cup B}(\omega) = \max \big( \chi_A(\omega), \chi_B(\omega) \big), \, \forall \omega \in \Omega$
5. $\chi_{A \cap B}(\omega) = \min \big( \chi_A(\omega), \chi_B(\omega) \big), \, \forall \omega \in \Omega$

***

Как индикаторная функция поможет нам в определении предела последовательности множеств?

Пусть есть последовательность множеств $A_1, A_2, \ldots, A_n, \ldots$ $(A_k \subseteq \Omega)$.

1. Будем говорить, что существует предел последовательности множеств $\lim_{n \to \infty} A_n$, если существует предел последовательности индикаторных функций множеств этой последовательности $\lim_{n \to \infty} \chi_{A_n}(\omega)$.
2. Это равносильно тому, что для любого $\omega$ либо индикаторная функция $\chi_{A_n}(\omega) = 1$, начиная с некоторого номера $n_0$, либо индикаторная функция $\chi_{A_n}(\omega) = 0$, начиная с некоторого номера $\tilde n_0$.
3. Из этого следует, что предел последовательности индикаторных функций $\lim_{n \to \infty} \chi_{A_n} (\omega)$ будет равен либо нулю, либо единице.
4. Следовательно, будет является индикаторной функцией некоторого множества $A$.
5. Это множество $A$ мы по определению назовём **пределом последовательности множеств** $(A_n)_{n=1}^\infty$.

То же самое рассуждение, но без слов:

$$
\begin{split}
&\exists \lim_{n \to \infty} A_n \overset{\circled{1}}{\Leftarrow}
\forall \omega \in \Omega \, \exists \lim_{n \to \infty} \chi_{A_n} (\omega) \overset{\circled{2}}{\Leftrightarrow} \\
&\forall \omega \in \Omega \,\, 
\left [ 
\begin{aligned} 
\chi_{A_n} (\omega) &= 1, \forall n > n_0 \\
\chi_{A_n} (\omega) &= 0, \forall n > \tilde n_0 \end{aligned}
\right.
\overset{\circled{3}}{\Rightarrow} \\
& \lim_{n \to \infty} \chi_{A_n} (\omega) = 
\left [ 
\begin{aligned} 
&1 \\ 
&0 
\end{aligned} 
\right. \overset{\circled{4}}\Rightarrow 
\chi_{A_n}(\omega) \overset{\circled{5}}{\Rightarrow }
A \defin \lim_{n \to \infty} A_n
\end{split}
$$

:::{#def-lim-set-seq}
Пределом последовательности множеств $(A_n)_{n=1}^\infty$ называется множество $A$, индикаторная функция которого является пределом индикаторных функций множеств данной последовательности:

$$
A \defin \lim_{n \to \infty} A_n \Leftrightarrow \chi_A (\omega) = \lim_{n \to \infty} \chi_{A_n} (\omega)
$$
:::





```{=html}
<script type="text/javascript" src="./js/chapter.js"></script>
```
